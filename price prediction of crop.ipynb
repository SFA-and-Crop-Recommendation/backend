{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84442c5b-7ff6-40e8-8be6-1b9fc0576c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def fetch_and_save_commodity_data(params, commodity_name, filename=\"commodity_data.csv\"):\n",
    "    \"\"\"\n",
    "    Fetch commodity data from API, filter last 24 months, and save to CSV.\n",
    "    \"\"\"\n",
    "    api_key = \"579b464db66ec23bdd00000107d05e8dc0f44b2264e86594199d6d7f\"\n",
    "    url = \"https://api.data.gov.in/resource/35985678-0d79-46b4-9ed6-6f13308a1d24\"\n",
    "    \n",
    "    query_params = params.copy()\n",
    "    query_params.update({\n",
    "        \"api-key\": api_key,\n",
    "        \"format\": \"json\",\n",
    "        \"filters[Commodity]\": commodity_name,\n",
    "        \"limit\": 100000,\n",
    "        \"offset\": 0\n",
    "    })\n",
    "\n",
    "    response = requests.get(url, params=query_params)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'records' not in data or len(data['records']) == 0:\n",
    "        raise ValueError(f\"No records found for {commodity_name} with parameters {params}.\")\n",
    "\n",
    "    records = data['records']\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Preprocessing\n",
    "    df['Arrival_Date'] = pd.to_datetime(df['Arrival_Date'], dayfirst=True, errors='coerce')\n",
    "    df = df.dropna(subset=['Arrival_Date'])  # Drop invalid dates\n",
    "    df = df.sort_values('Arrival_Date')\n",
    "\n",
    "    # Filter last 24 months\n",
    "    latest_date = df['Arrival_Date'].max()\n",
    "    cutoff_date = latest_date - pd.DateOffset(months=24)\n",
    "    df = df[df['Arrival_Date'] >= cutoff_date]\n",
    "\n",
    "    df['Modal_Price'] = pd.to_numeric(df['Modal_Price'], errors='coerce')\n",
    "    df = df.dropna(subset=['Modal_Price'])\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {len(df)} records to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6443b3ce-79a4-445c-8f3f-186284346162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def train_and_predict_from_csv(filename=\"commodity_data.csv\"):\n",
    "    \"\"\"\n",
    "    Train LSTM model from CSV data and predict price 6 months later.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    df['Arrival_Date'] = pd.to_datetime(df['Arrival_Date'], dayfirst=True, errors='coerce')\n",
    "    df = df.sort_values('Arrival_Date')\n",
    "\n",
    "    if df.shape[0] < 50:\n",
    "        raise ValueError(f\"Not enough data to train model. Only {df.shape[0]} records found.\")\n",
    "\n",
    "    prices = df['Modal_Price'].values.reshape(-1, 1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_scaled = scaler.fit_transform(prices)\n",
    "\n",
    "    n_steps = 30\n",
    "\n",
    "    if len(prices_scaled) <= n_steps:\n",
    "        raise ValueError(f\"Not enough sequences for LSTM. Need more than {n_steps} records.\")\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(n_steps, len(prices_scaled)):\n",
    "        X.append(prices_scaled[i-n_steps:i, 0])\n",
    "        y.append(prices_scaled[i, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build Model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X.shape[1], 1)))  # <-- using Input layer properly\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X, y, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predict next 180 days (6 months)\n",
    "    future_steps = 180\n",
    "    last_sequence = prices_scaled[-n_steps:]\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for _ in range(future_steps):\n",
    "        pred_input = last_sequence.reshape((1, n_steps, 1))\n",
    "        pred_price = model.predict(pred_input, verbose=0)\n",
    "        predictions.append(pred_price[0, 0])\n",
    "\n",
    "        last_sequence = np.append(last_sequence[1:], pred_price[0, 0])\n",
    "\n",
    "    # Get final price after 180 days\n",
    "    future_price_scaled = predictions[-1]\n",
    "    future_price = scaler.inverse_transform(np.array(future_price_scaled).reshape(-1, 1))[0, 0]\n",
    "\n",
    "    return model, scaler, future_price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ab86d-5134-418f-85c0-c98acbaa4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the commodity name (e.g., Rice, Wheat, etc.):  Rice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 724 records to commodity_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Step 1: Fetch and Save the Commodity Data\n",
    "commodity_name = input(\"Enter the commodity name (e.g., Rice, Wheat, etc.): \")\n",
    "\n",
    "# Parameters for the commodity (example: West Bengal, Kolkata)\n",
    "params = {\n",
    "    \"filters[State]\": \"West Bengal\",\n",
    "    \"filters[District]\": \"Kolkata\"\n",
    "}\n",
    "\n",
    "filename = \"commodity_data.csv\"\n",
    "\n",
    "# Step 2: Fetch and save commodity data using the `fetch_and_save_commodity_data` function\n",
    "fetch_and_save_commodity_data(params, commodity_name, filename)\n",
    "\n",
    "# Step 3: Train the model and make a prediction\n",
    "try:\n",
    "    model, scaler, predicted_price = train_and_predict_from_csv(filename)\n",
    "    print(f\"Predicted Price for {commodity_name} after 6 months: {predicted_price:.2f} INR\")\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "# Step 4: Save the pipeline as a pickle file\n",
    "pkl_filename = \"commodity_price_prediction_pipeline.pkl\"\n",
    "model_pipeline = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'commodity_name': commodity_name,\n",
    "    'params': params\n",
    "}\n",
    "\n",
    "with open(pkl_filename, 'wb') as f:\n",
    "    pickle.dump(model_pipeline, f)\n",
    "\n",
    "print(f\"âœ… Full model pipeline saved as '{pkl_filename}'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d215ec-7ec3-4d61-a6b8-fc17cca8c90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
